# Bench our mid-level B-trees

# maximize lookahead buffer, we don't actually gc so we only get one pass
# of the disk for these tests
defines.LOOKAHEAD_SIZE = 'BLOCK_COUNT / 8'

[cases.bench_btree]
# 0 = in-order
# 1 = reversed-order
# 2 = random-order
defines.ORDER = [0, 1, 2]
defines.N = 1024
defines.STEP = 1
defines.SEED = 42
defines.SIZE = 4
in = 'lfs.c'
code = '''
    lfs_t lfs;
    lfs_init(&lfs, CFG) => 0;
    // create free lookahead
    memset(lfs.lookahead.buffer, 0, CFG->lookahead_size);
    lfs.lookahead.start = 0;
    lfs.lookahead.size = lfs_min(8*CFG->lookahead_size,
            CFG->block_count);
    lfs.lookahead.next = 0;
    lfs_alloc_ack(&lfs);

    // create a tree with N elements
    lfsr_btree_t btree = LFSR_BTREE_NULL;
    uint32_t prng = SEED;
    for (lfsr_bid_t i = 0; i < N; i++) {
        lfsr_bid_t i_
                = (ORDER == 0) ? i
                : (ORDER == 1) ? 0
                : BENCH_PRNG(&prng) % (lfsr_btree_weight(&btree)+1);
        // measure commits
        if (i % STEP == 0) {
            BENCH_START("commit", i, STEP);
        }
        uint8_t wbuf[SIZE];
        memset(wbuf, 'a'+(BENCH_PRNG(&prng) % 26), SIZE);
        lfsr_btree_commit(&lfs, &btree, LFSR_ATTRS(
                LFSR_ATTR(i_, DATA, +1, BUF(wbuf, SIZE)))) => 0;
        if (i % STEP == 0) {
            BENCH_STOP("commit");
        }

        // measure lookups
        if (i % STEP == 0) {
            BENCH_START("lookup", i, STEP);
            lfsr_bid_t i_ = BENCH_PRNG(&prng) % (i+1);
            lfsr_tag_t tag_;
            lfsr_bid_t weight_;
            lfsr_data_t data_;
            lfsr_btree_lookup(&lfs, &btree, i_,
                    &tag_, &weight_, &data_) => 0;
            assert(tag_ == LFSR_TAG_DATA);
            assert(weight_ == 1);
            assert(lfsr_data_size(&data_) == SIZE);
            BENCH_STOP("lookup");
        }

        // measure disk usage
        if (i % STEP == 0) {
            lfs_off_t count = 0;

            lfsr_btraversal_t traversal = LFSR_BTRAVERSAL();
            while (true) {
                lfsr_binfo_t binfo;
                int err = lfsr_btraversal_read(&lfs, &btree, &traversal,
                        &binfo);
                assert(!err || err == LFS_ERR_NOENT);
                if (err == LFS_ERR_NOENT) {
                    break;
                }

                if (binfo.tag == LFSR_TAG_BRANCH) {
                    count += 1;
                }
            }

            BENCH_RESULT("usage", i, STEP,
                (uintmax_t)count * CFG->block_size);
        }
    }
'''

#[cases.bench_btree_lookup]
#defines.N = [8, 16, 32, 64, 128, 256, 1024]
## 0 = in-order
## 1 = reversed-order
## 2 = random-order
#defines.ORDER = [0, 1, 2]
#defines.SEED = 42
#in = 'lfs.c'
#code = '''
#    lfs_t lfs;
#    lfs_init(&lfs, CFG) => 0;
#    // create free lookahead
#    memset(lfs.lookahead.buffer, 0, CFG->lookahead_size);
#    lfs.lookahead.start = 0;
#    lfs.lookahead.size = lfs_min(8*CFG->lookahead_size,
#            CFG->block_count);
#    lfs.lookahead.next = 0;
#    lfs_alloc_ack(&lfs);
#
#    uint32_t prng = SEED;
#
#    // create a tree with N elements
#    lfsr_btree_t btree = LFSR_BTREE_NULL;
#    const char *alphas = "abcdefghijklmnopqrstuvwxyz";
#    for (lfs_size_t i = 0; i < N; i++) {
#        lfs_off_t i_
#                = (ORDER == 0) ? i
#                : (ORDER == 1) ? 0
#                : BENCH_PRNG(&prng) % (lfsr_btree_weight(&btree)+1);
#        lfsr_btree_push(&lfs, &btree, i_, LFSR_TAG_DATA, 1,
#                LFSR_DATA_BUF(&alphas[i % 26], 1)) => 0;
#    }
#
#    // assume an unfetched btree
#    btree.root.off = 0;
#
#    // bench lookup
#    BENCH_START();
#    lfs_size_t i = BENCH_PRNG(&prng) % N;
#    uint8_t buffer[4];
#    lfsr_tag_t tag_;
#    lfs_size_t weight_;
#    
#    lfsr_btree_get(&lfs, &btree, i,
#            &tag_, &weight_, buffer, 4) => 1;
#    assert(tag_ == LFSR_TAG_DATA);
#    assert(weight_ == 1);
#    BENCH_STOP();
#'''
#
#[cases.bench_btree_commit]
#defines.N = [8, 16, 32, 64, 128, 256, 1024]
## 0 = in-order
## 1 = reversed-order
## 2 = random-order
#defines.ORDER = [0, 1, 2]
#defines.SEED = 42
#defines.AMORTIZED = false
#in = 'lfs.c'
#code = '''
#    lfs_t lfs;
#    lfs_init(&lfs, CFG) => 0;
#    // create free lookahead
#    memset(lfs.lookahead.buffer, 0, CFG->lookahead_size);
#    lfs.lookahead.start = 0;
#    lfs.lookahead.size = lfs_min(8*CFG->lookahead_size,
#            CFG->block_count);
#    lfs.lookahead.next = 0;
#    lfs_alloc_ack(&lfs);
#
#    uint32_t prng = SEED;
#
#    // create a tree with N elements
#    if (AMORTIZED) {
#        BENCH_START();
#    }
#    lfsr_btree_t btree = LFSR_BTREE_NULL;
#    const char *alphas = "abcdefghijklmnopqrstuvwxyz";
#    for (lfs_size_t i = 0; i < N; i++) {
#        lfs_off_t i_
#                = (ORDER == 0) ? i
#                : (ORDER == 1) ? 0
#                : BENCH_PRNG(&prng) % (lfsr_btree_weight(&btree)+1);
#        lfsr_btree_push(&lfs, &btree, i_, LFSR_TAG_DATA, 1,
#                LFSR_DATA_BUF(&alphas[i % 26], 1)) => 0;
#    }
#
#    // bench appending a new id
#    if (!AMORTIZED) {
#        BENCH_START();
#    }
#    lfs_size_t i = BENCH_PRNG(&prng) % N;
#    lfsr_btree_push(&lfs, &btree, i, LFSR_TAG_DATA, 1,
#            LFSR_DATA_BUF(&alphas[i % 26], 1)) => 0;
#    BENCH_STOP();
#
#    uint8_t buffer[4];
#    lfsr_tag_t tag_;
#    lfs_size_t weight_;
#
#    lfsr_btree_get(&lfs, &btree, i,
#            &tag_, &weight_, buffer, 4) => 1;
#    assert(tag_ == LFSR_TAG_DATA);
#    assert(weight_ == 1);
#'''
#
